# Kubernetes attachdetach failed on Azure blob # 

Tags: kubernetes, azure

I have sometimes strange error on attaching drive from Azure that causes problem with detaching and attaching Azure blob type volume to another machine. It happens always when Kubernetes tries to move container with attached volume to another node. It looks like Azure storage lease is incorrectly released by terminated pod and due to this lease still exists on first machine when another tries to get the same blob volume. Here goes Events part from `kubectl describe pod ...`:

```text
Events:
  FirstSeen	LastSeen	Count	From				SubObjectPath	Type		Reason		Message
  ---------	--------	-----	----				-------------	--------	------		-------
  8m		8m		1	default-scheduler				Normal		Scheduled	Successfully assigned mongo-database-1327438630-6zqmg to k8s-agent-123123qwe-0
  2m		2m		1	attachdetach					Warning		FailedMount	Failed to attach volume "azure" on node "k8s-agent-123123qwe-0" with: Attach volume "mongo.vhd" to instance "k8s-agent-123123qwe-0" failed with compute.VirtualMachinesClient#CreateOrUpdate: Failure sending request: StatusCode=200 -- Original Error: Long running operation terminated with status 'Failed': Code="DiskBlobAlreadyInUseByAnotherDisk" Message="Blob https://123123123qweqweqwe.blob.core.windows.net/vhds/mongo.vhd is already in use by another disk belonging to VM 'k8s-agent-123123qwe-1'. You can examine the blob metadata for the disk reference information."
  6m		1m		3	kubelet, k8s-agent-123123qwe-0			Warning		FailedMount	Unable to mount volumes for pod "mongo-database-1327438630-6zqmg_default(5e385476-8358-11e7-9833-000d3a2aad6a)": timeout expired waiting for volumes to attach/mount for pod "default"/"mongo-database-1327438630-6zqmg". list of unattached/unmounted volumes=[azure]
  6m		1m		3	kubelet, k8s-agent-123123qwe-0			Warning		FailedSync	Error syncing pod, skipping: timeout expired waiting for volumes to attach/mount for pod "default"/"mongo-database-1327438630-6zqmg". list of unattached/unmounted volumes=[azure]
  2m		52s		8	kubelet, k8s-agent-123123qwe-0			Warning		FailedMount	MountVolume.MountDevice failed for volume "kubernetes.io/azure-disk/mongo.vhd" (spec.Name: "azure") pod "5e385476-8358-11e7-9833-000d3a2aad6a" (UID: "5e385476-8358-11e7-9833-000d3a2aad6a") with: exit status 1

```
In given log machine k8s-agent-123123qwe-0 tries to instantiate mongo pod which was previously deployed on k8s-agent-123123qwe-1. I use some easy volume definition in pod but if I use PVC and PV it has the same issue. 

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mongo-database
  labels:
    app: mongo-database
    tier: bases
    area: app1
spec:
  ports:
  - port: 27017
    protocol: TCP
    name: tcp-27017
    targetPort: 27017
  selector:
    app: mongo-database
    tier: bases
    area: app1
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: mongo-database
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: mongo-database
        tier: bases
        area: app1
    spec:
      containers:
        - image: mongo:latest
          name: mongo-database
          resources:
            requests:
              memory: "250Mi"
              cpu: "250m"
            limits:
              memory: "500Mi"
              cpu: "500m"
          ports:
          - containerPort: 27017
          volumeMounts:
            - name: azure
              mountPath: /data/db
      volumes:
        - name: azure
          azureDisk:
            diskName: mongo.vhd
            diskURI: https://123123123qweqweqwe.blob.core.windows.net/vhds/mongo.vhd
```
I have to use blob volume for mongodb because of problems with permissions when using Azure File Service. My Azure ACS Kubernetes cluster, which is Ubuntu based cannot handle permissions with SMB protocol. I get following error: 

```text
2017-08-17T16:32:01.093+0000 E STORAGE  [initandlisten] WiredTiger error (17) [1502987521:93935][1:0x7f127eb88d00], connection: /data/db/WiredTiger.wt: handle-open: open: File exists
2017-08-17T16:32:01.137+0000 I STORAGE  [initandlisten] WiredTiger message unexpected file WiredTiger.wt found, renamed to WiredTiger.wt.1
2017-08-17T16:32:01.157+0000 E STORAGE  [initandlisten] WiredTiger error (1) [1502987521:157631][1:0x7f127eb88d00], connection: /data/db/WiredTiger.wt: handle-open: open: Operation not permitted
2017-08-17T16:32:01.170+0000 I -        [initandlisten] Assertion: 28595:1: Operation not permitted src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine.cpp 269
2017-08-17T16:32:01.178+0000 I STORAGE  [initandlisten] exception in initAndListen: 28595 1: Operation not permitted, terminating
```
For PostgreSQL I can use Azure File Service which is good.  

Only when it (attachdetach problem) occurs I have to manually go to Azure Portal and disconnect blob disc device from first machine and if it doesn't help do the same on second machine. Pod then will attach this device back to machine. 

I have to figure out some solution. 